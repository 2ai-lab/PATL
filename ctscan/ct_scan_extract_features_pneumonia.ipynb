{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Tenforflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read image file paths and store to a list both for pneumonia and normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Files Count\n",
      "Normal: 6332\n",
      "pneumonia: 6334\n",
      "Total: 12666\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../../dataset/ctscan/3A_images_resized/all\"\n",
    "\n",
    "all_files = []\n",
    "\n",
    "pneumonia_files = glob.glob(os.path.join(dataset_path, \"Pneumonia\", \"*.png\"))\n",
    "pneumonia_files.extend(glob.glob(os.path.join(dataset_path, \"Pneumonia\", \"*.jpg\")))\n",
    "\n",
    "normal_files = glob.glob(os.path.join(dataset_path, \"Normal\", \"*.png\"))\n",
    "normal_files.extend(glob.glob(os.path.join(dataset_path, \"Normal\", \"*.jpg\")))\n",
    "\n",
    "# Get all the files from the directory in a two element list.\n",
    "# First element is list of file location to pneumonia images and second element is list of file location to Normal images.\n",
    "all_files = [normal_files, pneumonia_files]\n",
    "print(\"Image Files Count\\nNormal: {}\\npneumonia: {}\\nTotal: {}\".format(len(normal_files), len(pneumonia_files), len(all_files[0] + all_files[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_count = pneumonia_count = 2500 # 2500 or 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read image from file list and store the corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(files, label, data_count, img_size, image_id_count):\n",
    "  dataset = []  # List to hold all the dataset. Each element is a dictionary\n",
    "\n",
    "  count = 1\n",
    "  for j in tqdm(files):  # Loop over each file location\n",
    "    data_dict = {}\n",
    "    data_dict[\"id\"] = image_id_count\n",
    "    data_dict[\"filepath\"] = j\n",
    "    try:\n",
    "      img = cv2.imread(j)\n",
    "      img = cv2.resize(img, (img_size, img_size))\n",
    "      data_dict[\"image\"] = img\n",
    "      data_dict[\"label\"] = label\n",
    "      dataset.append(data_dict)\n",
    "      if count == data_count:\n",
    "        break\n",
    "      count += 1\n",
    "      image_id_count += 1\n",
    "    except Exception as e:\n",
    "      print(\"faulty image: {} {}\".format(j, e))\n",
    "  return dataset, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read image from the file and store the corresponding label in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████▍                                              | 2499/6332 [00:20<00:32, 119.20it/s]\n",
      " 39%|██████████████████████████████▍                                              | 2499/6334 [00:17<00:27, 139.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Count\n",
      "Normal: 2500\n",
      "pneumonia: 2500\n",
      "Total: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c_dataset, nc_dataset, t_dataset = [], [], []\n",
    "image_id_count = 0       # Count to record the ids of files. Each file has a unique ID.\n",
    "img_size = 224\n",
    "# all_files => [NC, C]\n",
    "for i, data in enumerate(all_files): # only two loops for pneumonia and Normal\n",
    "  if i == 0:\n",
    "    nc_dataset, image_id_count = get_dataset(data, i, normal_count, img_size, image_id_count)\n",
    "  else:\n",
    "    c_dataset, image_id_count = get_dataset(data, i, pneumonia_count, img_size, image_id_count)\n",
    "tot_dataset = nc_dataset + c_dataset\n",
    "print(\"Dataset Count\\nNormal: {}\\npneumonia: {}\\nTotal: {}\".format(len(nc_dataset), len(c_dataset), len(tot_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract image only from the dataset to send to DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_only = []\n",
    "for data in tot_dataset:\n",
    "  image_only.append(data[\"image\"])\n",
    "image_only = np.array(image_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 224, 224, 3)\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(image_only.shape)\n",
    "total_ds = pneumonia_count + normal_count\n",
    "image_only = image_only[:total_ds]\n",
    "batch_size = int(image_only.shape[0] / 2) if total_ds > 5000 else image_only.shape[0]\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate batches of images to feed into DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_img = img_datagen.flow(image_only, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to select a model from three (VGG16, ResNet101 and DenseNet169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_models(img_size, model_sel):\n",
    "  if model_sel == 1:\n",
    "    vgg_pre_t = VGG16(input_shape=(img_size, img_size, 3), include_top=False, weights ='imagenet')\n",
    "    return vgg_pre_t, 25088\n",
    "\n",
    "  elif model_sel == 2:\n",
    "    resnet_pre_t= ResNet101(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n",
    "    return resnet_pre_t, 100352\n",
    "\n",
    "  elif model_sel == 3:\n",
    "    densenet169_pre_t = DenseNet169(input_shape=(img_size, img_size, 3), include_top=False, weights ='imagenet' )\n",
    "    return densenet169_pre_t, 81536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select model among 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model = 2 # int(input(\"Enter the number for: \\n 1) VGG16 \\n 2) Resnet101  \\n 3) Densenet169 \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract image feature from the selected DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 7s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:32<00:00, 92.64s/it]\n"
     ]
    }
   ],
   "source": [
    "all_features, reduced_features = [], []\n",
    "pca = PCA(n_components=batch_size)\n",
    "\n",
    "all_feat = []\n",
    "model, feature_size = all_models(img_size, select_model)\n",
    "for data in tqdm(range(len(batch_img))):\n",
    "  try:\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(batch_size, feature_size)\n",
    "    feature_matrix = features.reshape(features.shape[0], -1)\n",
    "    reduced_features = pca.fit_transform(feature_matrix)\n",
    "  except:\n",
    "    img_len = len(batch_img[data])\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(img_len, feature_size)\n",
    "    feature_matrix = features.reshape(features.shape[0], -1)\n",
    "    reduced_features = pca.fit_transform(feature_matrix)\n",
    "  all_feat.extend(reduced_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace image value by image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "{'id': 0, 'filepath': '../../dataset/ctscan/3A_images_resized/all\\\\Normal\\\\Normal_1671_793_0000.png', 'image': array([-5.1546894e+01,  5.1121563e-01, -9.4625206e+00, ...,\n",
      "       -2.0666956e-04,  3.2767650e-05,  8.2749648e-05], dtype=float32), 'label': 0}\n",
      "{'id': 2500, 'filepath': '../../dataset/ctscan/3A_images_resized/all\\\\Pneumonia\\\\CP_1072_3115_0037.png', 'image': array([4.8701744e+00, 6.6690707e+00, 6.0499935e+00, ..., 1.9359033e-04,\n",
      "       5.5109460e-05, 8.3378371e-05], dtype=float32), 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tot_dataset[:total_ds])):\n",
    "  tot_dataset[i]['image'] = all_feat[i]\n",
    "\n",
    "# print sample dataset pneumonia and Normal\n",
    "print(len(tot_dataset))\n",
    "print(tot_dataset[0])\n",
    "print(tot_dataset[2500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save extracted feature in pickle file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../pickle_files/al/ct_scan/pneumonia_\"\n",
    "if select_model == 1:\n",
    "  filename = f\"ct_scan_pca_{len(tot_dataset)}_vgg16.pickle\"\n",
    "elif select_model == 2:\n",
    "  filename = f\"ct_scan_pca_{len(tot_dataset)}_resnet101.pickle\"\n",
    "elif select_model == 3:\n",
    "  filename = f\"ct_scan_pca_{len(tot_dataset)}_densenet169.pickle\"\n",
    "\n",
    "file = filepath + filename\n",
    "with open(file, 'wb') as handle:\n",
    "  pickle.dump(tot_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
